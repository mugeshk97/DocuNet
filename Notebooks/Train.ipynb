{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c679309",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpu = tf.config.experimental.list_physical_devices('GPU')[0]\n",
    "tf.config.experimental.set_memory_growth(gpu, True)\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733f07d5",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f3f5124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_v1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, 360, 360, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_1 (Conv2D)                 (None, 360, 360, 64) 640         input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "act_1 (Activation)              (None, 360, 360, 64) 0           conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "pool_1 (MaxPooling2D)           (None, 180, 180, 64) 0           act_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv_2 (Conv2D)                 (None, 180, 180, 64) 36928       pool_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "act_2 (Activation)              (None, 180, 180, 64) 0           conv_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "pool_2 (MaxPooling2D)           (None, 90, 90, 64)   0           act_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv_3 (Conv2D)                 (None, 90, 90, 32)   18464       pool_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "act_3 (Activation)              (None, 90, 90, 32)   0           conv_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "pool_3 (MaxPooling2D)           (None, 45, 45, 32)   0           act_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv_4 (Conv2D)                 (None, 45, 45, 16)   4624        pool_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "act_4 (Activation)              (None, 45, 45, 16)   0           conv_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "pool_4 (MaxPooling2D)           (None, 22, 22, 16)   0           act_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool_5 (MaxPooling2D)           (None, 11, 11, 16)   0           pool_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 1936)         0           pool_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           123968      flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 32)           2080        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "black_border (Dense)            (None, 1)            33          dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "good (Dense)                    (None, 1)            33          dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gridline (Dense)                (None, 1)            33          dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "shaded (Dense)                  (None, 1)            33          dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 186,836\n",
      "Trainable params: 186,836\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_ = tf.keras.layers.Input(shape=(360,360,1), name =\"input\")\n",
    "\n",
    "conv_1 = tf.keras.layers.Conv2D(filters = 64, kernel_size = (3,3), padding = \"same\", name=\"conv_1\")(input_)\n",
    "act_1 = tf.keras.layers.Activation('relu', name='act_1')(conv_1)\n",
    "pool_1 = tf.keras.layers.MaxPool2D(pool_size = (2,2), name = \"pool_1\")(act_1)\n",
    "\n",
    "conv_2 = tf.keras.layers.Conv2D(filters = 64, kernel_size = (3,3), padding = \"same\" , name=\"conv_2\")(pool_1)\n",
    "act_2 = tf.keras.layers.Activation('relu', name='act_2')(conv_2)\n",
    "pool_2 = tf.keras.layers.MaxPool2D(pool_size = (2,2), name = \"pool_2\")(act_2)\n",
    "\n",
    "conv_3 = tf.keras.layers.Conv2D(filters = 32, kernel_size = (3,3), padding = \"same\",  name=\"conv_3\")(pool_2)\n",
    "act_3 = tf.keras.layers.Activation('relu', name='act_3')(conv_3)\n",
    "pool_3 = tf.keras.layers.MaxPool2D(pool_size = (2,2), name = \"pool_3\")(act_3)\n",
    "\n",
    "conv_4 = tf.keras.layers.Conv2D(filters = 16, kernel_size = (3,3), padding = \"same\", name=\"conv_4\")(pool_3)\n",
    "act_4 = tf.keras.layers.Activation('relu', name='act_4')(conv_4)\n",
    "pool_4 = tf.keras.layers.MaxPool2D(pool_size = (2,2), name = \"pool_4\")(act_4)\n",
    "pool_5 = tf.keras.layers.MaxPool2D(pool_size = (2,2), name = \"pool_5\")(pool_4)\n",
    "\n",
    "flatten = tf.keras.layers.Flatten(name=\"flatten\")(pool_5)\n",
    "\n",
    "\n",
    "dense_1 = tf.keras.layers.Dense(64, activation='relu', name = \"dense_1\")(flatten)\n",
    "dense_2 = tf.keras.layers.Dense(32, activation='relu', name = \"dense_2\")(dense_1)\n",
    "\n",
    "shaded = tf.keras.layers.Dense(1,activation='sigmoid', name=\"shaded\")(dense_2)\n",
    "gridline = tf.keras.layers.Dense(1,activation='sigmoid', name=\"gridline\")(dense_2)\n",
    "good = tf.keras.layers.Dense(1,activation='sigmoid', name=\"good\")(dense_2)\n",
    "black_border = tf.keras.layers.Dense(1,activation='sigmoid', name=\"black_border\")(dense_2)\n",
    "\n",
    "model_outputs = [black_border, good, gridline, shaded]\n",
    "model = tf.keras.models.Model(input_, model_outputs, name =\"model_v1\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a88d7f",
   "metadata": {},
   "source": [
    "## Compile "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f5fdc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss={\n",
    "        \"shaded\": 'binary_crossentropy',\n",
    "        \"gridline\": \"binary_crossentropy\",\n",
    "        \"good\": \"binary_crossentropy\",\n",
    "        \"black_border\": \"binary_crossentropy\"\n",
    "    },\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555e71be",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8dd47887",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_directory, shape):\n",
    "    classes = os.listdir(file_directory)\n",
    "    indices = {}\n",
    "    data = []\n",
    "    y = []\n",
    "    for i in range(len(classes)):\n",
    "        sub_dir = os.path.join(file_directory, classes[i])\n",
    "        filename = os.listdir(sub_dir)\n",
    "        for file_ in filename:\n",
    "            file_path = os.path.join(sub_dir, file_)\n",
    "            img = cv2.imread(file_path,0)\n",
    "            img= cv2.resize(img, shape)\n",
    "            img = img / 255.0\n",
    "            img = np.expand_dims(img, axis=-1)\n",
    "            data.append(img)\n",
    "            y.append(i)\n",
    "        indices[i] = classes[i]\n",
    "    print(indices)\n",
    "    return np.array(data), tf.one_hot(np.array(y), depth= 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8576e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'black_border', 1: 'good', 2: 'gridline', 3: 'shaded'}\n"
     ]
    }
   ],
   "source": [
    "x_data, y_data = load_data('processed_data/', shape=(360,360))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a14f320e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([4]), (360, 360, 1))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data[0].shape, x_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bde91a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(713, 360, 360, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336b7376",
   "metadata": {},
   "source": [
    "## Seperating Targets for model input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c0e5c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "black = np.zeros((len(y_data), 1))\n",
    "goo = np.zeros((len(y_data), 1))\n",
    "grid =np.zeros((len(y_data), 1))\n",
    "shad = np.zeros((len(y_data), 1))\n",
    "for i, nu in enumerate(y_data):\n",
    "    black[i] = nu[0]\n",
    "    goo[i] = nu[1]\n",
    "    grid[i] = nu[2]\n",
    "    shad[i] = nu[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62b79573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(713, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "black.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d5636c",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f550439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "178/178 [==============================] - 7s 39ms/step - loss: 1.3056e-04 - black_border_loss: 3.0915e-05 - good_loss: 1.3361e-05 - gridline_loss: 7.1382e-05 - shaded_loss: 1.4900e-05 - black_border_accuracy: 1.0000 - good_accuracy: 1.0000 - gridline_accuracy: 1.0000 - shaded_accuracy: 1.0000\n",
      "Epoch 2/3\n",
      "178/178 [==============================] - 7s 39ms/step - loss: 6.9207e-05 - black_border_loss: 1.4878e-05 - good_loss: 5.5899e-06 - gridline_loss: 3.8751e-05 - shaded_loss: 9.9880e-06 - black_border_accuracy: 1.0000 - good_accuracy: 1.0000 - gridline_accuracy: 1.0000 - shaded_accuracy: 1.0000\n",
      "Epoch 3/3\n",
      "178/178 [==============================] - 7s 39ms/step - loss: 4.3669e-05 - black_border_loss: 8.7196e-06 - good_loss: 3.1981e-06 - gridline_loss: 2.4899e-05 - shaded_loss: 6.8527e-06 - black_border_accuracy: 1.0000 - good_accuracy: 1.0000 - gridline_accuracy: 1.0000 - shaded_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x_data, [black, goo, grid, shad],\n",
    "    steps_per_epoch= 713 // 4,\n",
    "    batch_size = 4,\n",
    "    epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "25c9d242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('DocuNet.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b0be2a",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "accf8f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = tf.keras.models.load_model('mtm5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "784acac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('document_data/black_border/00001431.tif')\n",
    "img = cv2.resize(img , (360,360))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a2044aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "_, img = cv2.threshold(img, 220, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7ad43faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.expand_dims(img, 0)\n",
    "img = np.expand_dims(img, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b837083b",
   "metadata": {},
   "outputs": [],
   "source": [
    "black_border_op, good_op, grid_op, shad_op = model.predict(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "82c07897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]] [[0.]] [[0.]] [[0.]]\n"
     ]
    }
   ],
   "source": [
    "print(black_border_op, good_op, grid_op, shad_op)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "497527df925e3e58bbbb33060083048cb69f2f4e35ce25c5100d412e1b31a1bf"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python388jvsc74a57bd0497527df925e3e58bbbb33060083048cb69f2f4e35ce25c5100d412e1b31a1bf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
